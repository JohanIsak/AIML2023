{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "\n",
    "#Tokenized & Lemmatized data\n",
    "data = pd.read_csv('../Trip Advisor Preprocessing/data_tokenized.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratings.overall\n",
       "aNegative     1577\n",
       "bNeutral      1945\n",
       "cPositive    19959\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing all values with sentiment labels as discussed in the paper\n",
    "\n",
    "data['ratings.overall'] = data['ratings.overall'].replace(range(0, 3), 'aNegative')\n",
    "data['ratings.overall'] = data['ratings.overall'].replace(3, 'bNeutral')\n",
    "data['ratings.overall'] = data['ratings.overall'].replace(range(4, 6), 'cPositive')\n",
    "\n",
    "result = data.groupby('ratings.overall').size()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataframing and turning input & outvariable to model-readable list. \n",
    "preprocessed_data = data['text'].tolist()\n",
    "labels = data['ratings.overall'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train split and subsequent validation / test splits. \n",
    "X_train, X_rem, y_train, y_rem = train_test_split(preprocessed_data,labels,train_size=0.75,stratify=labels) #75% train data\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5) #12.5% in test and 12.5% in validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1620 fits failed out of a total of 2430.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1620 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 729, in fit\n",
      "    self._update_class_log_prior(class_prior=class_prior)\n",
      "  File \"/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 565, in _update_class_log_prior\n",
      "    raise ValueError(\"Number of priors must match number of classes.\")\n",
      "ValueError: Number of priors must match number of classes.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.87484901 0.87826603 0.85712829 0.87526465 0.87439532 0.85200158\n",
      " 0.87478369 0.87327813 0.84723584 0.87484901 0.87826603 0.85712829\n",
      " 0.87526465 0.87439532 0.85200158 0.87478369 0.87327813 0.84723584\n",
      " 0.87484901 0.87826603 0.85712829 0.87526465 0.87439532 0.85200158\n",
      " 0.87478369 0.87327813 0.84723584 0.84892006 0.87437577 0.84624461\n",
      " 0.84105714 0.85385174 0.81858755 0.83759184 0.84731699 0.80187355\n",
      " 0.84892006 0.87437577 0.84624461 0.84105714 0.85385174 0.81858755\n",
      " 0.83759184 0.84731699 0.80187355 0.84892006 0.87437577 0.84624461\n",
      " 0.84105714 0.85385174 0.81858755 0.83759184 0.84731699 0.80187355\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87377305 0.85729922 0.84347308 0.87785621 0.88049906 0.85376486\n",
      " 0.8767469  0.87471039 0.85000625 0.87377305 0.85729922 0.84347308\n",
      " 0.87785621 0.88049906 0.85376486 0.8767469  0.87471039 0.85000625\n",
      " 0.87377305 0.85729922 0.84347308 0.87785621 0.88049906 0.85376486\n",
      " 0.8767469  0.87471039 0.85000625 0.86860844 0.86921942 0.85093822\n",
      " 0.84678866 0.86318112 0.81275971 0.83788258 0.8451436  0.78629358\n",
      " 0.86860844 0.86921942 0.85093822 0.84678866 0.86318112 0.81275971\n",
      " 0.83788258 0.8451436  0.78629358 0.86860844 0.86921942 0.85093822\n",
      " 0.84678866 0.86318112 0.81275971 0.83788258 0.8451436  0.78629358\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86381603 0.83279551 0.82747724 0.87634094 0.87706338 0.84840246\n",
      " 0.87721253 0.87871105 0.84763268 0.86381603 0.83279551 0.82747724\n",
      " 0.87634094 0.87706338 0.84840246 0.87721253 0.87871105 0.84763268\n",
      " 0.86381603 0.83279551 0.82747724 0.87634094 0.87706338 0.84840246\n",
      " 0.87721253 0.87871105 0.84763268 0.87258108 0.84667857 0.84602874\n",
      " 0.85760019 0.87659228 0.81850952 0.84620279 0.85891764 0.79035235\n",
      " 0.87258108 0.84667857 0.84602874 0.85760019 0.87659228 0.81850952\n",
      " 0.84620279 0.85891764 0.79035235 0.87258108 0.84667857 0.84602874\n",
      " 0.85760019 0.87659228 0.81850952 0.84620279 0.85891764 0.79035235\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'nb__alpha': 0.5, 'nb__class_prior': None, 'nb__fit_prior': True, 'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Best accuracy score:  0.880499064297329\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "# Define parameters for grid search\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "    'vect__max_df': [0.9, 0.95, 1.0],\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'nb__alpha': [0.1, 0.5, 1.0],  # Smoothing parameter (Laplace smoothing)\n",
    "    'nb__fit_prior': [True, False],  # Whether to learn class prior probabilities or not\n",
    "    'nb__class_prior': [None, [0.25, 0.75], [0.5, 0.5]],  # Prior probabilities of the classes\n",
    "}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best accuracy score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model used:  {'nb__alpha': 0.5, 'nb__class_prior': None, 'nb__fit_prior': True, 'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Validation set Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      0.68      0.68       201\n",
      "     Netural       0.41      0.39      0.40       254\n",
      "    Positive       0.94      0.94      0.94      2480\n",
      "\n",
      "    accuracy                           0.88      2935\n",
      "   macro avg       0.68      0.67      0.67      2935\n",
      "weighted avg       0.87      0.88      0.88      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the val data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_valid)\n",
    "print(\"Best model used: \", grid_search.best_params_)\n",
    "\n",
    "target_names = ['Negative', 'Netural', 'Positive']\n",
    "print('\\nValidation set Classification Report: \\n',classification_report(y_valid, y_pred_val, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.70      0.71       193\n",
      "     Netural       0.41      0.38      0.40       232\n",
      "    Positive       0.95      0.95      0.95      2511\n",
      "\n",
      "    accuracy                           0.89      2936\n",
      "   macro avg       0.69      0.68      0.68      2936\n",
      "weighted avg       0.89      0.89      0.89      2936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FINAL SCORING ON TEST DATA\n",
    "\n",
    "# Evaluate the best model on the val data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "target_names = ['Negative', 'Netural', 'Positive']\n",
    "print('\\nTest set Classification Report: \\n',classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 keywords for a Positive rating:\n",
      "1. great: -3.572\n",
      "2. hotel: -3.747\n",
      "3. room: -3.772\n",
      "4. staff: -3.982\n",
      "5. location: -4.079\n",
      "6. clean: -4.291\n",
      "7. stay: -4.321\n",
      "8. nice: -4.371\n",
      "9. good: -4.470\n",
      "10. service: -4.574\n",
      "\n",
      "Top 10 keywords for a Neutral rating:\n",
      "1. room: -3.755\n",
      "2. hotel: -4.053\n",
      "3. good: -4.298\n",
      "4. location: -4.389\n",
      "5. clean: -4.657\n",
      "6. great: -4.697\n",
      "7. nice: -4.868\n",
      "8. staff: -4.969\n",
      "9. stay: -5.116\n",
      "10. small: -5.170\n",
      "\n",
      "Top 10 keywords for a Negative rating:\n",
      "1. room: -3.822\n",
      "2. hotel: -4.131\n",
      "3. stay: -4.846\n",
      "4. dirty: -5.004\n",
      "5. staff: -5.026\n",
      "6. nt: -5.048\n",
      "7. service: -5.136\n",
      "8. location: -5.361\n",
      "9. bed: -5.369\n",
      "10. good: -5.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johanisak/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#This part was developed in collaboration with ChatGPT based on the metric logarithmic probability chosen by the project group. \n",
    "\n",
    "# Extract top 10 keywords that have an implication on the model classifying it as 'bad'\n",
    "feature_names = best_model.named_steps['vect'].get_feature_names()\n",
    "top10_bad_idx = best_model.named_steps['nb'].feature_log_prob_[0, :].argsort()[::-1][:10]\n",
    "top10_bad_keywords = [(feature_names[i], best_model.named_steps['nb'].feature_log_prob_[0, i]) for i in top10_bad_idx]\n",
    "\n",
    "\n",
    "# Extract top 10 keywords that have an implication on the model classifying it as 'neutral'\n",
    "top10_neutral_idx = best_model.named_steps['nb'].feature_log_prob_[1, :].argsort()[::-1][:10]\n",
    "top10_neutral_keywords = [(feature_names[i], best_model.named_steps['nb'].feature_log_prob_[1, i]) for i in top10_neutral_idx]\n",
    "\n",
    "\n",
    "# Extract top 10 keywords that have an implication on the model classifying it as 'good'\n",
    "top10_good_idx = best_model.named_steps['nb'].feature_log_prob_[2, :].argsort()[::-1][:10]\n",
    "top10_good_keywords = [(feature_names[i], best_model.named_steps['nb'].feature_log_prob_[2, i]) for i in top10_good_idx]\n",
    "\n",
    "\n",
    "# Display top 10 keywords that have an implication on the model classifying it as a 5-star rating\n",
    "print(\"Top 10 keywords for a Positive rating:\")\n",
    "for i, (keyword, value) in enumerate(top10_good_keywords):\n",
    "    print(f\"{i+1}. {keyword}: {value:.3f}\")\n",
    "\n",
    "# Display top 10 keywords that have an implication on the model classifying it as a 1-star rating\n",
    "print(\"\\nTop 10 keywords for a Neutral rating:\")\n",
    "for i, (keyword, value) in enumerate(top10_neutral_keywords):\n",
    "    print(f\"{i+1}. {keyword}: {value:.3f}\")\n",
    "\n",
    "\n",
    "# Display top 10 keywords that have an implication on the model classifying it as a 1-star rating\n",
    "print(\"\\nTop 10 keywords for a Negative rating:\")\n",
    "for i, (keyword, value) in enumerate(top10_bad_keywords):\n",
    "    print(f\"{i+1}. {keyword}: {value:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING DC DATA ON MODEL\n",
    "\n",
    "The following is a test on the above trained model on data from a city not included in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratings.overall\n",
       "1.0     28\n",
       "2.0     27\n",
       "3.0     80\n",
       "4.0    374\n",
       "5.0    679\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the Washington DC only dataset for geographic test on unseen data. \n",
    "data_DC = pd.read_csv('../Trip Advisor Preprocessing/data_tokenized_DC.csv')\n",
    "\n",
    "import_DC = data_DC.groupby('ratings.overall').size()\n",
    "import_DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratings.overall\n",
       "aNegative      55\n",
       "bNeutral       80\n",
       "cPositive    1053\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing all values with sentiment labels as discussed in the paper\n",
    "data_DC['ratings.overall'] = data_DC['ratings.overall'].replace(range(0, 3), 'aNegative')\n",
    "data_DC['ratings.overall'] = data_DC['ratings.overall'].replace(3, 'bNeutral')\n",
    "data_DC['ratings.overall'] = data_DC['ratings.overall'].replace(range(4, 6), 'cPositive')\n",
    "\n",
    "result_DC = data_DC.groupby('ratings.overall').size()\n",
    "\n",
    "result_DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract preprocessed data and labels\n",
    "preprocessed_data_DC = data_DC['text'].tolist()\n",
    "labels_DC = data_DC['ratings.overall'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model used:  {'nb__alpha': 0.5, 'nb__class_prior': None, 'nb__fit_prior': True, 'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "DC set Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.56      0.61        55\n",
      "     Netural       0.40      0.40      0.40        80\n",
      "    Positive       0.95      0.96      0.96      1053\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.67      0.64      0.65      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_DC = best_model.predict(preprocessed_data_DC)\n",
    "\n",
    "print(\"Best model used: \", grid_search.best_params_)\n",
    "\n",
    "target_names_DC = ['Negative', 'Netural', 'Positive']\n",
    "print('\\nDC set Classification Report: \\n',classification_report(labels_DC, y_pred_DC, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
